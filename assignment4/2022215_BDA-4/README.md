# Wiki-Vote Kafka Streaming Project

Real-time graph analytics using Apache Kafka for the Wiki-Vote dataset.
for running all the different command see execution_guide.md

## ğŸ“‹ Project Overview

This project implements a complete streaming data pipeline using Apache Kafka to process and analyze the Wikipedia voting network dataset in real-time. It demonstrates:

- **Real-time data streaming** with Kafka
- **Graph metrics computation** (nodes, edges, degree distribution)
- **Sliding window analytics** for throughput monitoring
- **Fault tolerance** with state management
- **Live visualization** of streaming metrics

## ğŸ¯ Ground Truth Metrics

| Metric | Value |
|--------|-------|
| Nodes | 7,115 |
| Edges | 103,689 |
| Nodes in largest WCC | 7,066 (99.3%) |
| Edges in largest WCC | 103,663 (100%) |
| Average clustering coefficient | 0.1409 |
| Number of triangles | 608,389 |
| Diameter | 7 |

## ğŸš€ Quick Start

### Prerequisites

- Windows 10/11
- Java 17 or later
- Python 3.8 or later
- Apache Kafka (setup using provided PDF guide)

### Installation

1. **Run the setup script:**
```powershell
.\setup.ps1
```

2. **Or install manually:**
```bash
pip install -r requirements.txt
```

3. **Download dataset:**
```bash
# Download from: https://snap.stanford.edu/data/wiki-Vote.txt.gz
# Extract to get wiki-Vote.txt
```

## ğŸ“¦ Project Structure

```
wiki-vote-kafka/
â”œâ”€â”€ kafka_producer.py          # Basic producer for streaming edges
â”œâ”€â”€ kafka_consumer.py          # Basic consumer with metrics
â”œâ”€â”€ advanced_consumer.py       # Advanced consumer with windowing
â”œâ”€â”€ visualize_metrics.py       # Visualization script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup.ps1                  # Setup script
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ wiki-Vote.txt              # Dataset (download separately)
â”œâ”€â”€ plots/                     # Generated visualizations
â”œâ”€â”€ logs/                      # Log files
â””â”€â”€ state/                     # State checkpoints
```

## ğŸ”§ Usage

### Step 1: Start Kafka

Open PowerShell and start Kafka server:

```powershell
cd C:\kafka\kafka_2.13-4.1.0
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

### Step 2: Create Topic

In a new PowerShell window:

```powershell
cd C:\kafka\kafka_2.13-4.1.0
.\bin\windows\kafka-topics.bat --create --topic wiki-vote --bootstrap-server localhost:9092
```

### Step 3: Start Consumer

Choose one of the consumer options:

**Basic Consumer:**
```bash
python kafka_consumer.py
```

**Advanced Consumer (with windowing and state management):**
```bash
python advanced_consumer.py
```

### Step 4: Start Producer

In another PowerShell window:

```bash
# Basic streaming (1ms delay)
python kafka_producer.py --file wiki-Vote.txt

# Fast streaming (no delay)
python kafka_producer.py --file wiki-Vote.txt --delay 0

# Simulate out-of-order events
python kafka_producer.py --file wiki-Vote.txt --shuffle
```

### Step 5: Visualize Results

After streaming completes:

```bash
python visualize_metrics.py
```

## ğŸ“Š Features

### Part A: Data Streaming Setup âœ…

- âœ… Apache Kafka installation (KRaft mode)
- âœ… Topic creation (`wiki-vote`)
- âœ… Dataset preprocessing and streaming simulation
- âœ… Configurable delay for realistic streaming

### Part B: Streaming Computation âœ…

#### Basic Consumer Features:
- Real-time node and edge counting
- Progress tracking towards ground truth
- Throughput monitoring
- Degree distribution statistics

#### Advanced Consumer Features:
- **Sliding window metrics** (10-second windows)
- **State management** for fault tolerance
- **Time series data collection**
- **Periodic snapshots** for visualization

### Part C: Streaming Challenges âœ…

#### 1. Latency Testing
```bash
# Test different delays
python kafka_producer.py --file wiki-Vote.txt --delay 0.001  # 1ms
python kafka_producer.py --file wiki-Vote.txt --delay 0.01   # 10ms
python kafka_producer.py --file wiki-Vote.txt --delay 0.1    # 100ms
```

#### 2. Ordering Issues
```bash
# Simulate out-of-order events
python kafka_producer.py --file wiki-Vote.txt --shuffle
```

#### 3. Fault Tolerance
```bash
# Start consumer
python advanced_consumer.py

# Press Ctrl+C to stop (state is saved)
# Restart - it will resume from last checkpoint
python advanced_consumer.py
```

#### 4. State Management
- Automatic state checkpointing every 5,000 edges
- Persistent storage in `consumer_state.pkl`
- Seamless recovery on restart

## ğŸ“ˆ Outputs

### Console Output

**Producer:**
```
âœ“ Producer connected to Kafka at localhost:9092
âœ“ Publishing to topic: wiki-vote
âœ“ Loaded 103689 edges from dataset

Progress: 10000/103689 (9.6%) | Rate: 1234.5 edges/sec | Edge: 123 â†’ 456
Progress: 20000/103689 (19.3%) | Rate: 1456.7 edges/sec | Edge: 789 â†’ 012
...
âœ“ Streaming completed!
Total edges streamed: 103689
Average rate: 1500.00 edges/sec
```

**Consumer:**
```
[12:34:56] Edges: 10000
  Nodes: 3421 | Edges: 9987
  Overall rate: 1234.5 edges/sec
  Window rate: 1456.2 edges/sec (last 10s)
  Progress: Nodes 48.1% | Edges 9.6%
```

### Generated Visualizations

1. **metrics_over_time.png** - Time series of nodes, edges, and processing rate
2. **rate_histogram.png** - Distribution of processing rates
3. **cumulative_progress.png** - Progress towards ground truth

### Data Files

- **metrics_timeseries.json** - Time series data for further analysis
- **consumer_state.pkl** - Checkpoint for fault recovery

## ğŸ“ Assignment Deliverables

### Code Files âœ…
- âœ… `kafka_producer.py` - Producer implementation
- âœ… `kafka_consumer.py` - Basic consumer
- âœ… `advanced_consumer.py` - Advanced consumer with windowing

### Report Components âœ…

1. **Real-time Metric Plots** - Generated by `visualize_metrics.py`
2. **Streaming Challenges Discussion:**
   - Latency effects documented
   - Out-of-order handling tested
   - Fault tolerance demonstrated
   - State management implemented

## ğŸ” Streaming Issues Explored

### 1. Latency Impact

**Experiment:**
- Vary producer delay: 0ms, 1ms, 10ms, 100ms
- Observe consumer processing lag
- Measure end-to-end latency

**Observations:**
- Lower delays increase throughput but require more resources
- Window-based metrics show rate fluctuations
- Consumer keeps pace with producer at reasonable delays

### 2. Event Ordering

**Experiment:**
- Use `--shuffle` flag to randomize edge order
- Compare results with sequential processing

**Observations:**
- Graph metrics remain consistent (commutative operations)
- Sliding window rates show more variance
- Demonstrates eventual consistency

### 3. Fault Tolerance

**Experiment:**
- Stop consumer mid-stream (Ctrl+C)
- Restart consumer
- Verify offset management

**Results:**
- Consumer resumes from last committed offset
- No data loss
- State restored from checkpoint

### 4. State Management

**Implementation:**
- Periodic state snapshots every 5,000 edges
- Serialized state in pickle format
- Automatic recovery on startup

**Benefits:**
- Crash recovery
- Resumable processing
- Consistent metrics across restarts

## ğŸ› ï¸ Troubleshooting

### Kafka Connection Issues

```bash
# Check if Kafka is running
netstat -an | findstr 9092

# Verify topic exists
cd C:\kafka\kafka_2.13-4.1.0
.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
```

### Consumer Not Receiving Messages

```bash
# Reset consumer group offset
cd C:\kafka\kafka_2.13-4.1.0
.\bin\windows\kafka-consumer-groups.bat --bootstrap-server localhost:9092 --group wiki-vote-consumer --reset-offsets --to-earliest --topic wiki-vote --execute
```

### Dataset Download Issues

If automatic download fails:
1. Visit: https://snap.stanford.edu/data/wiki-Vote.html
2. Download `wiki-Vote.txt.gz`
3. Extract to get `wiki-Vote.txt`
4. Place in project directory

## ğŸ“ Command Reference

### Producer Commands

```bash
# Basic streaming
python kafka_producer.py --file wiki-Vote.txt

# Custom delay (seconds)
python kafka_producer.py --file wiki-Vote.txt --delay 0.01

# Shuffle for out-of-order simulation
python kafka_producer.py --file wiki-Vote.txt --shuffle

# Custom Kafka server
python kafka_producer.py --file wiki-Vote.txt --server localhost:9092
```

### Consumer Commands

```bash
# Basic consumer
python kafka_consumer.py

# Report every 5000 edges
python kafka_consumer.py --interval 5000

# Enable degree statistics
python kafka_consumer.py --degrees

# Advanced consumer with custom window
python advanced_consumer.py --window 30
```

### Visualization Commands

```bash
# Generate all plots
python visualize_metrics.py

# Custom input file
python visualize_metrics.py --input my_metrics.json

# Save to specific directory
python visualize_metrics.py --output-dir ./plots
```

## ğŸ“š Additional Resources

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [SNAP Dataset Collection](https://snap.stanford.edu/data/)
- [Kafka Python Client](https://kafka-python.readthedocs.io/)

## ğŸ¤ Contributing

Feel free to extend this project with:
- Additional graph metrics (clustering coefficient, connected components)
- Real-time visualization dashboard
- Multi-consumer parallel processing
- Integration with Apache Storm or Flink

## ğŸ“„ License

This project is for educational purposes as part of a data streaming course assignment.

---

**Created for:** Data Streaming Assignment - Wiki-Vote Graph Analytics
**Date:** November 2024