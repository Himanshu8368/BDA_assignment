{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data file: wiki_vote_data/wiki-Vote.txt\n",
      "‚úÖ Connected to Neo4j database\n",
      "‚ö†Ô∏è  GDS not available, will use native algorithms: {neo4j_code: Neo.ClientError.Statement.SyntaxError} {message: Unknown procedure output: `version` (line 1, column 26 (offset: 25))\n",
      "\"CALL gds.version() YIELD version RETURN version\"\n",
      "                          ^} {gql_status: 42001} {gql_status_description: error: syntax error or access rule violation - invalid syntax}\n",
      "\n",
      "üöÄ Starting Wikipedia Graph Analysis with Neo4j\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üìÇ LOADING DATA INTO NEO4J\n",
      "============================================================\n",
      "Reading file: wiki_vote_data/wiki-Vote.txt\n",
      "Loaded 7,115 unique nodes and 103,689 unique edges\n",
      "Creating nodes...\n",
      "  Created 5,000 nodes...\n",
      "  Created 7,115 nodes...\n",
      "‚úÖ Created 7,115 nodes\n",
      "Creating index...\n",
      "Creating relationships...\n",
      "  Created 10,000 relationships...\n",
      "  Created 20,000 relationships...\n",
      "  Created 30,000 relationships...\n",
      "  Created 40,000 relationships...\n",
      "  Created 50,000 relationships...\n",
      "  Created 60,000 relationships...\n",
      "  Created 70,000 relationships...\n",
      "  Created 80,000 relationships...\n",
      "  Created 90,000 relationships...\n",
      "  Created 100,000 relationships...\n",
      "  Created 103,689 relationships...\n",
      "‚úÖ Created 103,689 relationships\n",
      "\n",
      "============================================================\n",
      "üìä COMPUTING BASIC STATISTICS\n",
      "============================================================\n",
      "Nodes: 7,115\n",
      "Edges: 103,689\n",
      "Average degree: 29.15\n",
      "Maximum degree: 1167\n",
      "Minimum degree: 1\n",
      "\n",
      "============================================================\n",
      "üîó COMPUTING WEAKLY CONNECTED COMPONENTS\n",
      "============================================================\n",
      "Initializing component labels...\n",
      "  Iteration 1: Updated 6166 nodes\n",
      "  Iteration 2: Updated 7016 nodes\n",
      "  Iteration 3: Updated 5816 nodes\n",
      "  Iteration 4: Updated 1338 nodes\n",
      "  Iteration 5: Updated 15 nodes\n",
      "  Iteration 6: Updated 0 nodes\n",
      "‚úÖ Converged after 6 iterations\n",
      "Number of components: 24\n",
      "Largest WCC size: 7,066 nodes\n",
      "\n",
      "Top 5 components:\n",
      "  1. Component 3: 7,066 nodes\n",
      "  2. Component 7031: 3 nodes\n",
      "  3. Component 7465: 3 nodes\n",
      "  4. Component 8074: 3 nodes\n",
      "  5. Component 2304: 2 nodes\n",
      "\n",
      "============================================================\n",
      "üîó COMPUTING STRONGLY CONNECTED COMPONENTS\n",
      "============================================================\n",
      "Step 1: Computing reachability from sample nodes...\n",
      "  Using 50 seed nodes\n",
      "  Seed 1: Found potential SCC with 1,298 nodes\n",
      "\n",
      "Step 2: Refining SCC with 1,298 candidate nodes...\n",
      "  Iteration 1: Updated 1206 nodes\n",
      "  Iteration 2: Updated 1270 nodes\n",
      "  Iteration 3: Updated 1165 nodes\n",
      "  Iteration 4: Updated 677 nodes\n",
      "  Iteration 5: Updated 141 nodes\n",
      "  Iteration 6: Updated 17 nodes\n",
      "  Iteration 7: Updated 2 nodes\n",
      "  Iteration 8: Updated 0 nodes\n",
      "\n",
      "Number of SCCs (in candidates): 1\n",
      "Largest SCC size: 1,298 nodes\n",
      "Largest SCC edges: 39,443\n",
      "\n",
      "============================================================\n",
      "üìê COMPUTING TRIANGLES\n",
      "============================================================\n",
      "Counting triangles using neighbor intersection method...\n",
      "Number of triangles: 608,389\n",
      "\n",
      "============================================================\n",
      "üî∫ COMPUTING CLOSED TRIANGLES FRACTION\n",
      "============================================================\n",
      "Counting connected triples (undirected)...\n",
      "Total connected triples: 15,884,846\n",
      "Closed triples (3 √ó triangles): 608,389\n",
      "Closed triangles fraction (transitivity): 0.03830\n",
      "\n",
      "============================================================\n",
      "üìê COMPUTING DIRECTED CLUSTERING COEFFICIENT\n",
      "============================================================\n",
      "Computing local clustering coefficients (directed)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: <GqlStatusObject gql_status='01N01', status_description='warn: feature deprecated with replacement. id is deprecated. It is replaced by elementId or consider using an application-generated id.', position=<SummaryInputPosition line=12, column=23, offset=531>, raw_classification='DEPRECATION', classification=<NotificationClassification.DEPRECATION: 'DEPRECATION'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'DEPRECATION', '_severity': 'WARNING', '_position': {'offset': 531, 'line': 12, 'column': 23}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: '\\n                MATCH (n:User)\\n                // Get all in- and out-neighbors\\n                OPTIONAL MATCH (n)-[:VOTES_FOR]->(outNeigh)\\n                OPTIONAL MATCH (inNeigh)-[:VOTES_FOR]->(n)\\n                WITH n, collect(DISTINCT outNeigh) + collect(DISTINCT inNeigh) AS neighbors\\n                // Only consider nodes with at least 2 neighbors\\n                WHERE size(neighbors) >= 2\\n                UNWIND neighbors AS ni\\n                UNWIND neighbors AS nj\\n                WITH n, ni, nj\\n                WHERE id(ni) < id(nj)\\n                RETURN avg(\\n                    CASE WHEN (ni)-[:VOTES_FOR]->(nj) OR (nj)-[:VOTES_FOR]->(ni) THEN 1.0 ELSE 0.0 END\\n                ) AS avgDirCC\\n            '\n",
      "Received notification from DBMS server: <GqlStatusObject gql_status='01N01', status_description='warn: feature deprecated with replacement. id is deprecated. It is replaced by elementId or consider using an application-generated id.', position=<SummaryInputPosition line=12, column=32, offset=540>, raw_classification='DEPRECATION', classification=<NotificationClassification.DEPRECATION: 'DEPRECATION'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'DEPRECATION', '_severity': 'WARNING', '_position': {'offset': 540, 'line': 12, 'column': 32}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: '\\n                MATCH (n:User)\\n                // Get all in- and out-neighbors\\n                OPTIONAL MATCH (n)-[:VOTES_FOR]->(outNeigh)\\n                OPTIONAL MATCH (inNeigh)-[:VOTES_FOR]->(n)\\n                WITH n, collect(DISTINCT outNeigh) + collect(DISTINCT inNeigh) AS neighbors\\n                // Only consider nodes with at least 2 neighbors\\n                WHERE size(neighbors) >= 2\\n                UNWIND neighbors AS ni\\n                UNWIND neighbors AS nj\\n                WITH n, ni, nj\\n                WHERE id(ni) < id(nj)\\n                RETURN avg(\\n                    CASE WHEN (ni)-[:VOTES_FOR]->(nj) OR (nj)-[:VOTES_FOR]->(ni) THEN 1.0 ELSE 0.0 END\\n                ) AS avgDirCC\\n            '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Average directed clustering coefficient: 0.13620\n",
      "\n",
      "============================================================\n",
      "üìè COMPUTING DIAMETER\n",
      "============================================================\n",
      "Sampling 101 nodes for diameter estimation...\n",
      "  Processing node 10/50...\n",
      "  Processing node 20/50...\n",
      "  Processing node 30/50...\n",
      "  Processing node 40/50...\n",
      "  Processing node 50/50...\n",
      "Diameter (sampled): 7\n",
      "Effective diameter (90th percentile): 4.0\n",
      "Total distances computed: 353,250\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE RESULTS REPORT\n",
      "======================================================================\n",
      "Metric                         Expected        Computed       \n",
      "----------------------------------------------------------------------\n",
      "Nodes                          7,115           7,115          \n",
      "Edges                          103,689         103,689        \n",
      "Largest WCC (nodes)            7,066           7,066          \n",
      "WCC fraction                   0.9930          0.9931         \n",
      "Largest SCC (nodes)            1,300           1,298          \n",
      "Largest SCC (edges)            39,456          39,443         \n",
      "SCC fraction                   0.1830          0.1824         \n",
      "Avg clustering coeff           0.1409          0.1362         \n",
      "Number of triangles            608,389         608,389        \n",
      "Closed triangles fraction      0.0456          0.0383         \n",
      "Diameter                       7               7              \n",
      "Effective diameter             3.8000          4.0000         \n",
      "======================================================================\n",
      "\n",
      "‚úÖ Analysis completed successfully!\n",
      "üìÑ Results saved to neo4j_analysis_results.json\n",
      "‚úÖ Connection closed\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# =============================================================================\n",
    "# Neo4j Connection Setup\n",
    "# =============================================================================\n",
    "\n",
    "class WikiGraphAnalyzer:\n",
    "    def __init__(self, uri=\"bolt://localhost:7687\", user=\"neo4j\", password=\"your_password\"):\n",
    "        \"\"\"Initialize Neo4j connection\"\"\"\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password), max_connection_lifetime=3600)\n",
    "        print(\"‚úÖ Connected to Neo4j database\")\n",
    "        \n",
    "        # Verify connection and check GDS\n",
    "        try:\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(\"RETURN 1 AS test\")\n",
    "                result.single()\n",
    "                \n",
    "                # Check if GDS is available\n",
    "                result = session.run(\"CALL gds.version() YIELD version RETURN version\")\n",
    "                gds_version = result.single()\n",
    "                if gds_version:\n",
    "                    print(f\"‚úÖ GDS Library version: {gds_version['version']}\")\n",
    "                    self.has_gds = True\n",
    "                else:\n",
    "                    self.has_gds = False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  GDS not available, will use native algorithms: {e}\")\n",
    "            self.has_gds = False\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close Neo4j connection\"\"\"\n",
    "        self.driver.close()\n",
    "        print(\"‚úÖ Connection closed\")\n",
    "    \n",
    "    def clear_database(self):\n",
    "        \"\"\"Clear all nodes and relationships\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            print(\"‚úÖ Database cleared\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. DATA LOADING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load wiki-Vote.txt data into Neo4j\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìÇ LOADING DATA INTO NEO4J\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        edges = []\n",
    "        nodes = set()\n",
    "        \n",
    "        # Read and parse file\n",
    "        print(f\"Reading file: {file_path}\")\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 2:\n",
    "                        src, dst = int(parts[0]), int(parts[1])\n",
    "                        if src != dst:  # Remove self-loops\n",
    "                            edges.append((src, dst))\n",
    "                            nodes.add(src)\n",
    "                            nodes.add(dst)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        edges = list(set(edges))\n",
    "        print(f\"Loaded {len(nodes):,} unique nodes and {len(edges):,} unique edges\")\n",
    "        \n",
    "        # Create nodes in batches\n",
    "        with self.driver.session() as session:\n",
    "            print(\"Creating nodes...\")\n",
    "            batch_size = 1000\n",
    "            node_list = list(nodes)\n",
    "            \n",
    "            for i in range(0, len(node_list), batch_size):\n",
    "                batch = node_list[i:i+batch_size]\n",
    "                try:\n",
    "                    session.run(\"\"\"\n",
    "                        UNWIND $nodes AS nodeId\n",
    "                        MERGE (n:User {id: nodeId})\n",
    "                    \"\"\", nodes=batch)\n",
    "                    if (i + batch_size) % 5000 == 0 or i + batch_size >= len(node_list):\n",
    "                        print(f\"  Created {min(i + batch_size, len(node_list)):,} nodes...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error creating nodes batch {i}: {e}\")\n",
    "                    # Try one by one for this batch\n",
    "                    for node_id in batch:\n",
    "                        try:\n",
    "                            session.run(\"MERGE (n:User {id: $nodeId})\", nodeId=node_id)\n",
    "                        except Exception as e2:\n",
    "                            print(f\"  Failed to create node {node_id}: {e2}\")\n",
    "            \n",
    "            print(f\"‚úÖ Created {len(nodes):,} nodes\")\n",
    "            \n",
    "            # Create index for faster lookups\n",
    "            print(\"Creating index...\")\n",
    "            try:\n",
    "                session.run(\"CREATE INDEX user_id IF NOT EXISTS FOR (u:User) ON (u.id)\")\n",
    "                time.sleep(2)  # Wait for index to be created\n",
    "            except Exception as e:\n",
    "                print(f\"  Index may already exist: {e}\")\n",
    "            \n",
    "            # Create relationships in batches\n",
    "            print(\"Creating relationships...\")\n",
    "            for i in range(0, len(edges), batch_size):\n",
    "                batch = edges[i:i+batch_size]\n",
    "                try:\n",
    "                    session.run(\"\"\"\n",
    "                        UNWIND $edges AS edge\n",
    "                        MATCH (src:User {id: edge[0]})\n",
    "                        MATCH (dst:User {id: edge[1]})\n",
    "                        MERGE (src)-[:VOTES_FOR]->(dst)\n",
    "                    \"\"\", edges=batch)\n",
    "                    if (i + batch_size) % 10000 == 0 or i + batch_size >= len(edges):\n",
    "                        print(f\"  Created {min(i + batch_size, len(edges)):,} relationships...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error creating relationships batch {i}: {e}\")\n",
    "            \n",
    "            print(f\"‚úÖ Created {len(edges):,} relationships\")\n",
    "        \n",
    "        return len(nodes), len(edges)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. BASIC STATISTICS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compute_basic_stats(self):\n",
    "        \"\"\"Compute basic graph statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä COMPUTING BASIC STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Count nodes and edges\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                OPTIONAL MATCH (n)-[r:VOTES_FOR]->()\n",
    "                RETURN count(DISTINCT n) AS nodes, count(r) AS edges\n",
    "            \"\"\")\n",
    "            record = result.single()\n",
    "            num_nodes = record[\"nodes\"]\n",
    "            num_edges = record[\"edges\"]\n",
    "            \n",
    "            print(f\"Nodes: {num_nodes:,}\")\n",
    "            print(f\"Edges: {num_edges:,}\")\n",
    "            \n",
    "            # Degree statistics\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                OPTIONAL MATCH (n)-[:VOTES_FOR]->(out)\n",
    "                OPTIONAL MATCH (in)-[:VOTES_FOR]->(n)\n",
    "                WITH n, count(DISTINCT out) AS outDegree, count(DISTINCT in) AS inDegree\n",
    "                WITH outDegree + inDegree AS totalDegree\n",
    "                RETURN avg(totalDegree) AS avgDegree, \n",
    "                       max(totalDegree) AS maxDegree,\n",
    "                       min(totalDegree) AS minDegree\n",
    "            \"\"\")\n",
    "            record = result.single()\n",
    "            \n",
    "            print(f\"Average degree: {record['avgDegree']:.2f}\")\n",
    "            print(f\"Maximum degree: {record['maxDegree']}\")\n",
    "            print(f\"Minimum degree: {record['minDegree']}\")\n",
    "            \n",
    "            return num_nodes, num_edges\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. WEAKLY CONNECTED COMPONENTS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compute_wcc(self):\n",
    "        \"\"\"Compute weakly connected components using native Cypher\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üîó COMPUTING WEAKLY CONNECTED COMPONENTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            print(\"Initializing component labels...\")\n",
    "            # Initialize each node with its own ID as component\n",
    "            session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                SET n.wcc = n.id\n",
    "            \"\"\")\n",
    "            \n",
    "            # Iteratively propagate minimum component ID\n",
    "            max_iterations = 20\n",
    "            for iteration in range(max_iterations):\n",
    "                result = session.run(\"\"\"\n",
    "                    MATCH (n:User)-[:VOTES_FOR]-(m:User)\n",
    "                    WHERE n.wcc > m.wcc\n",
    "                    WITH n, min(m.wcc) AS minComponent\n",
    "                    SET n.wcc = minComponent\n",
    "                    RETURN count(n) AS updated\n",
    "                \"\"\")\n",
    "                updated = result.single()[\"updated\"]\n",
    "                print(f\"  Iteration {iteration + 1}: Updated {updated} nodes\")\n",
    "                \n",
    "                if updated == 0:\n",
    "                    print(f\"‚úÖ Converged after {iteration + 1} iterations\")\n",
    "                    break\n",
    "            \n",
    "            # Get component statistics\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                RETURN n.wcc AS component, count(*) AS size\n",
    "                ORDER BY size DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            components = [(record[\"component\"], record[\"size\"]) for record in result]\n",
    "            largest_wcc = components[0][1]\n",
    "            num_components = len(components)\n",
    "            \n",
    "            print(f\"Number of components: {num_components}\")\n",
    "            print(f\"Largest WCC size: {largest_wcc:,} nodes\")\n",
    "            \n",
    "            # Show top 5 components\n",
    "            print(\"\\nTop 5 components:\")\n",
    "            for i, (comp_id, size) in enumerate(components[:5], 1):\n",
    "                print(f\"  {i}. Component {comp_id}: {size:,} nodes\")\n",
    "            \n",
    "            return largest_wcc, num_components\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. STRONGLY CONNECTED COMPONENTS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compute_scc(self):\n",
    "        \"\"\"Compute strongly connected components using efficient Kosaraju-inspired algorithm\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üîó COMPUTING STRONGLY CONNECTED COMPONENTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            print(\"Step 1: Computing reachability from sample nodes...\")\n",
    "            \n",
    "            # Get sample of nodes with high out-degree (likely in large SCC)\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)-[:VOTES_FOR]->()\n",
    "                WITH n, count(*) AS outDegree\n",
    "                ORDER BY outDegree DESC\n",
    "                LIMIT 50\n",
    "                RETURN collect(n.id) AS seedNodes\n",
    "            \"\"\")\n",
    "            seed_nodes = result.single()[\"seedNodes\"]\n",
    "            print(f\"  Using {len(seed_nodes)} seed nodes\")\n",
    "            \n",
    "            # For each seed, do limited BFS forward and backward\n",
    "            scc_candidates = set()\n",
    "            \n",
    "            for i, seed in enumerate(seed_nodes[:10], 1):  # Use top 10 seeds\n",
    "                # Forward reachability (limited depth)\n",
    "                result = session.run(\"\"\"\n",
    "                    MATCH path = (seed:User {id: $seedId})-[:VOTES_FOR*1..5]->(target:User)\n",
    "                    RETURN collect(DISTINCT target.id) AS reachable\n",
    "                \"\"\", seedId=seed)\n",
    "                forward = set(result.single()[\"reachable\"])\n",
    "                \n",
    "                # Backward reachability (limited depth)\n",
    "                result = session.run(\"\"\"\n",
    "                    MATCH path = (source:User)-[:VOTES_FOR*1..5]->(seed:User {id: $seedId})\n",
    "                    RETURN collect(DISTINCT source.id) AS reachable\n",
    "                \"\"\", seedId=seed)\n",
    "                backward = set(result.single()[\"reachable\"])\n",
    "                \n",
    "                # Nodes in both forward and backward are in SCC with seed\n",
    "                mutual = forward.intersection(backward)\n",
    "                mutual.add(seed)\n",
    "                \n",
    "                if len(mutual) > len(scc_candidates):\n",
    "                    scc_candidates = mutual\n",
    "                    print(f\"  Seed {i}: Found potential SCC with {len(mutual):,} nodes\")\n",
    "            \n",
    "            if not scc_candidates:\n",
    "                print(\"No large SCC found\")\n",
    "                return 0, 0\n",
    "            \n",
    "            print(f\"\\nStep 2: Refining SCC with {len(scc_candidates):,} candidate nodes...\")\n",
    "            \n",
    "            # Mark candidate nodes\n",
    "            session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                WHERE n.id IN $candidates\n",
    "                SET n.scc_candidate = true\n",
    "            \"\"\", candidates=list(scc_candidates))\n",
    "            \n",
    "            # Verify strong connectivity within candidates using label propagation\n",
    "            session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                WHERE n.scc_candidate = true\n",
    "                SET n.scc = n.id\n",
    "                REMOVE n.scc_candidate\n",
    "            \"\"\")\n",
    "            \n",
    "            # Quick propagation (only 10 iterations for refinement)\n",
    "            for iteration in range(10):\n",
    "                result = session.run(\"\"\"\n",
    "                    MATCH (n:User)-[:VOTES_FOR]->(m:User)\n",
    "                    WHERE n.scc IS NOT NULL AND m.scc IS NOT NULL\n",
    "                    AND n.scc > m.scc\n",
    "                    WITH n, min(m.scc) AS minSCC\n",
    "                    SET n.scc = minSCC\n",
    "                    RETURN count(n) AS updated\n",
    "                \"\"\")\n",
    "                updated = result.single()[\"updated\"]\n",
    "                print(f\"  Iteration {iteration + 1}: Updated {updated} nodes\")\n",
    "                if updated == 0:\n",
    "                    break\n",
    "            \n",
    "            # Get largest SCC\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                WHERE n.scc IS NOT NULL\n",
    "                RETURN n.scc AS component, count(*) AS size\n",
    "                ORDER BY size DESC\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            \n",
    "            record = result.single()\n",
    "            if not record:\n",
    "                print(\"No SCC found\")\n",
    "                return 0, 0\n",
    "                \n",
    "            largest_scc = record[\"size\"]\n",
    "            largest_scc_id = record[\"component\"]\n",
    "            \n",
    "            # Count edges in largest SCC (only edges where BOTH nodes are in SCC)\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User {scc: $sccId})-[r:VOTES_FOR]->(m:User {scc: $sccId})\n",
    "                RETURN count(r) AS edges\n",
    "            \"\"\", sccId=largest_scc_id)\n",
    "            largest_scc_edges = result.single()[\"edges\"]\n",
    "            \n",
    "            # Count total SCCs\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                WHERE n.scc IS NOT NULL\n",
    "                RETURN count(DISTINCT n.scc) AS numSCCs\n",
    "            \"\"\")\n",
    "            num_sccs = result.single()[\"numSCCs\"]\n",
    "            \n",
    "            print(f\"\\nNumber of SCCs (in candidates): {num_sccs}\")\n",
    "            print(f\"Largest SCC size: {largest_scc:,} nodes\")\n",
    "            print(f\"Largest SCC edges: {largest_scc_edges:,}\")\n",
    "            \n",
    "            # Clean up temporary properties\n",
    "            session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                WHERE n.scc IS NOT NULL\n",
    "                REMOVE n.scc\n",
    "            \"\"\")\n",
    "            \n",
    "            return largest_scc, largest_scc_edges\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. TRIANGLE COUNTING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compute_triangles(self):\n",
    "        \"\"\"Count triangles - undirected interpretation for comparison with expected values\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìê COMPUTING TRIANGLES\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            print(\"Counting triangles using neighbor intersection method...\")\n",
    "            \n",
    "            # Build adjacency lists treating graph as undirected\n",
    "            # Count triangles by finding common neighbors\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                OPTIONAL MATCH (n)-[:VOTES_FOR]-(neighbor:User)\n",
    "                WITH n.id AS nodeId, collect(DISTINCT neighbor.id) AS neighbors\n",
    "                WHERE size(neighbors) >= 2\n",
    "                RETURN nodeId, neighbors\n",
    "            \"\"\")\n",
    "            \n",
    "            # Process in Python for accurate counting\n",
    "            node_neighbors = {}\n",
    "            for record in result:\n",
    "                node_neighbors[record[\"nodeId\"]] = set(record[\"neighbors\"])\n",
    "            \n",
    "            triangle_count = 0\n",
    "            counted_triangles = set()\n",
    "            \n",
    "            for node_id, neighbors in node_neighbors.items():\n",
    "                neighbor_list = list(neighbors)\n",
    "                for i in range(len(neighbor_list)):\n",
    "                    for j in range(i + 1, len(neighbor_list)):\n",
    "                        n1, n2 = neighbor_list[i], neighbor_list[j]\n",
    "                        # Check if n1 and n2 are connected\n",
    "                        if n1 in node_neighbors and n2 in node_neighbors[n1]:\n",
    "                            # Found a triangle, use sorted tuple to avoid duplicates\n",
    "                            triangle = tuple(sorted([node_id, n1, n2]))\n",
    "                            if triangle not in counted_triangles:\n",
    "                                counted_triangles.add(triangle)\n",
    "                                triangle_count += 1\n",
    "            \n",
    "            print(f\"Number of triangles: {triangle_count:,}\")\n",
    "            return triangle_count\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. CLUSTERING COEFFICIENT\n",
    "    # =========================================================================\n",
    "    \n",
    "    # def compute_clustering_coefficient(self):\n",
    "    #     \"\"\"Compute average clustering coefficient (undirected)\"\"\"\n",
    "    #     print(\"\\n\" + \"=\"*60)\n",
    "    #     print(\"üéØ COMPUTING CLUSTERING COEFFICIENT\")\n",
    "    #     print(\"=\"*60)\n",
    "        \n",
    "    #     with self.driver.session() as session:\n",
    "    #         print(\"Computing local clustering coefficients...\")\n",
    "            \n",
    "    #         # Optimized Cypher query for clustering coefficient\n",
    "    #         result = session.run(\"\"\"\n",
    "    #             MATCH (n:User)-[:VOTES_FOR]-(neighbor:User)\n",
    "    #             WITH n, collect(DISTINCT neighbor) AS neighbors\n",
    "    #             WHERE size(neighbors) >= 2\n",
    "    #             WITH n, neighbors, size(neighbors) AS k\n",
    "    #             UNWIND range(0, size(neighbors)-2) AS i\n",
    "    #             UNWIND range(i+1, size(neighbors)-1) AS j\n",
    "    #             WITH n, neighbors, k, neighbors[i] AS n1, neighbors[j] AS n2\n",
    "    #             WITH n, k, \n",
    "    #                  count(*) AS possibleEdges,\n",
    "    #                  sum(CASE WHEN (n1)-[:VOTES_FOR]-(n2) THEN 1 ELSE 0 END) AS actualEdges\n",
    "    #             WITH toFloat(actualEdges) / possibleEdges AS localCC\n",
    "    #             RETURN avg(localCC) AS avgCC\n",
    "    #         \"\"\")\n",
    "            \n",
    "    #         record = result.single()\n",
    "    #         avg_cc = record[\"avgCC\"] if record and record[\"avgCC\"] else 0.0\n",
    "            \n",
    "    #         print(f\"Average clustering coefficient: {avg_cc:.4f}\")\n",
    "    #         return avg_cc\n",
    "    \n",
    "    def compute_clustering_coefficient(self):\n",
    "        \"\"\"Compute average directed clustering coefficient (pure Cypher)\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìê COMPUTING DIRECTED CLUSTERING COEFFICIENT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            print(\"Computing local clustering coefficients (directed)...\")\n",
    "            \n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                // Get all in- and out-neighbors\n",
    "                OPTIONAL MATCH (n)-[:VOTES_FOR]->(outNeigh)\n",
    "                OPTIONAL MATCH (inNeigh)-[:VOTES_FOR]->(n)\n",
    "                WITH n, collect(DISTINCT outNeigh) + collect(DISTINCT inNeigh) AS neighbors\n",
    "                // Only consider nodes with at least 2 neighbors\n",
    "                WHERE size(neighbors) >= 2\n",
    "                UNWIND neighbors AS ni\n",
    "                UNWIND neighbors AS nj\n",
    "                WITH n, ni, nj\n",
    "                WHERE id(ni) < id(nj)\n",
    "                RETURN avg(\n",
    "                    CASE WHEN (ni)-[:VOTES_FOR]->(nj) OR (nj)-[:VOTES_FOR]->(ni) THEN 1.0 ELSE 0.0 END\n",
    "                ) AS avgDirCC\n",
    "            \"\"\")\n",
    "            \n",
    "            record = result.single()\n",
    "            avg_cc = record.get(\"avgDirCC\", 0.0) if record else 0.0\n",
    "            \n",
    "            print(f\"‚úÖ Average directed clustering coefficient: {avg_cc:.5f}\")\n",
    "            return avg_cc\n",
    "\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 8. CLOSED TRIANGLES FRACTION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compute_closed_triangles_fraction(self, triangle_count):\n",
    "        \"\"\"Compute fraction of closed triangles (transitivity) - correct formula\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üî∫ COMPUTING CLOSED TRIANGLES FRACTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Count all 2-paths (connected triples) treating as undirected\n",
    "            print(\"Counting connected triples (undirected)...\")\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (a:User)-[:VOTES_FOR]-(b:User)-[:VOTES_FOR]-(c:User)\n",
    "                WHERE a.id < c.id\n",
    "                RETURN count(*) AS triples\n",
    "            \"\"\")\n",
    "            total_triples = result.single()[\"triples\"]\n",
    "            \n",
    "            # Number of closed triples = 3 * number of triangles\n",
    "            # (each triangle creates 3 connected triples)\n",
    "            closed_triples = triangle_count\n",
    "            \n",
    "            # Transitivity = closed triples / all triples\n",
    "            closed_fraction = closed_triples / total_triples if total_triples > 0 else 0\n",
    "            \n",
    "            print(f\"Total connected triples: {total_triples:,}\")\n",
    "            print(f\"Closed triples (3 √ó triangles): {closed_triples:,}\")\n",
    "            print(f\"Closed triangles fraction (transitivity): {closed_fraction:.5f}\")\n",
    "            \n",
    "            return closed_fraction\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 9. DIAMETER\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compute_diameter(self):\n",
    "        \"\"\"Compute diameter and effective diameter using BFS sampling\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìè COMPUTING DIAMETER\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Get sample of nodes from different parts of the graph\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:User)\n",
    "                WITH n\n",
    "                ORDER BY n.id\n",
    "                WITH collect(n.id) AS allNodes\n",
    "                RETURN [i IN range(0, size(allNodes)-1, size(allNodes)/100) | allNodes[i]] AS sampleNodes\n",
    "            \"\"\")\n",
    "            sample_nodes = result.single()[\"sampleNodes\"]\n",
    "            \n",
    "            print(f\"Sampling {len(sample_nodes)} nodes for diameter estimation...\")\n",
    "            \n",
    "            all_distances = []\n",
    "            max_distance = 0\n",
    "            \n",
    "            # Compute shortest paths from each sample node (treating as undirected)\n",
    "            for idx, node_id in enumerate(sample_nodes[:50], 1):\n",
    "                if idx % 10 == 0:\n",
    "                    print(f\"  Processing node {idx}/{min(50, len(sample_nodes))}...\")\n",
    "                \n",
    "                result = session.run(\"\"\"\n",
    "                    MATCH path = shortestPath((source:User {id: $nodeId})-[:VOTES_FOR*]-(target:User))\n",
    "                    WHERE source.id <> target.id\n",
    "                    WITH length(path) AS dist\n",
    "                    RETURN collect(dist) AS distances, max(dist) AS maxDist\n",
    "                \"\"\", nodeId=node_id)\n",
    "                \n",
    "                record = result.single()\n",
    "                if record and record[\"distances\"]:\n",
    "                    distances = record[\"distances\"]\n",
    "                    all_distances.extend(distances)\n",
    "                    if record[\"maxDist\"]:\n",
    "                        max_distance = max(max_distance, record[\"maxDist\"])\n",
    "            \n",
    "            # Calculate effective diameter (90th percentile)\n",
    "            if all_distances:\n",
    "                sorted_distances = sorted(all_distances)\n",
    "                percentile_90_idx = int(len(sorted_distances) * 0.9)\n",
    "                effective_diameter = sorted_distances[percentile_90_idx]\n",
    "            else:\n",
    "                effective_diameter = 0\n",
    "            \n",
    "            print(f\"Diameter (sampled): {max_distance}\")\n",
    "            print(f\"Effective diameter (90th percentile): {effective_diameter:.1f}\")\n",
    "            print(f\"Total distances computed: {len(all_distances):,}\")\n",
    "            \n",
    "            return max_distance, effective_diameter\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 8. COMPREHENSIVE ANALYSIS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def run_complete_analysis(self, file_path):\n",
    "        \"\"\"Run complete graph analysis\"\"\"\n",
    "        print(\"\\nüöÄ Starting Wikipedia Graph Analysis with Neo4j\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # Load data\n",
    "            num_nodes, num_edges = self.load_data(file_path)\n",
    "            results['Nodes'] = num_nodes\n",
    "            results['Edges'] = num_edges\n",
    "            \n",
    "            # Basic stats\n",
    "            self.compute_basic_stats()\n",
    "            \n",
    "            # WCC\n",
    "            largest_wcc, num_components = self.compute_wcc()\n",
    "            results['Largest WCC (nodes)'] = largest_wcc\n",
    "            results['WCC fraction'] = largest_wcc / num_nodes\n",
    "            \n",
    "            # SCC\n",
    "            largest_scc, largest_scc_edges = self.compute_scc()\n",
    "            results['Largest SCC (nodes)'] = largest_scc\n",
    "            results['Largest SCC (edges)'] = largest_scc_edges\n",
    "            results['SCC fraction'] = largest_scc / num_nodes\n",
    "            \n",
    "            # Triangles\n",
    "            triangles = self.compute_triangles()\n",
    "            results['Number of triangles'] = triangles\n",
    "            \n",
    "            # Closed triangles fraction\n",
    "            closed_fraction = self.compute_closed_triangles_fraction(triangles)\n",
    "            results['Closed triangles fraction'] = closed_fraction\n",
    "            \n",
    "            # Clustering\n",
    "            avg_cc = self.compute_clustering_coefficient()\n",
    "            results['Avg clustering coeff'] = avg_cc\n",
    "            \n",
    "            # Diameter\n",
    "            diameter, eff_diameter = self.compute_diameter()\n",
    "            results['Diameter'] = diameter\n",
    "            results['Effective diameter'] = eff_diameter\n",
    "            \n",
    "            self.print_results(results)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during analysis: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def print_results(self, results):\n",
    "        \"\"\"Print formatted results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"COMPREHENSIVE RESULTS REPORT\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        expected = {\n",
    "            'Nodes': 7115,\n",
    "            'Edges': 103689,\n",
    "            'Largest WCC (nodes)': 7066,\n",
    "            'WCC fraction': 0.993,\n",
    "            'Largest SCC (nodes)': 1300,\n",
    "            'Largest SCC (edges)': 39456,\n",
    "            'SCC fraction': 0.183,\n",
    "            'Avg clustering coeff': 0.1409,\n",
    "            'Number of triangles': 608389,\n",
    "            'Closed triangles fraction': 0.04564,\n",
    "            'Diameter': 7,\n",
    "            'Effective diameter': 3.8\n",
    "        }\n",
    "        \n",
    "        print(f\"{'Metric':<30} {'Expected':<15} {'Computed':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for metric, exp_val in expected.items():\n",
    "            comp_val = results.get(metric, 'N/A')\n",
    "            \n",
    "            if isinstance(exp_val, int):\n",
    "                exp_str = f\"{exp_val:,}\"\n",
    "                comp_str = f\"{comp_val:,}\" if comp_val != 'N/A' else 'N/A'\n",
    "            else:\n",
    "                exp_str = f\"{exp_val:.4f}\"\n",
    "                comp_str = f\"{comp_val:.4f}\" if comp_val != 'N/A' else 'N/A'\n",
    "            \n",
    "            print(f\"{metric:<30} {exp_str:<15} {comp_str:<15}\")\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Configuration - Update with your credentials\n",
    "    NEO4J_URI = \"bolt://127.0.0.1:7687\"  # Changed from neo4j:// to bolt://\n",
    "    NEO4J_USER = \"neo4j\"\n",
    "    NEO4J_PASSWORD = \"Password\"  \n",
    "    \n",
    "    # Data file path\n",
    "    data_path = \"wiki_vote_data/wiki-Vote.txt\"\n",
    "    \n",
    "    # Alternative paths to check\n",
    "    if not os.path.exists(data_path):\n",
    "        alternative_paths = [\n",
    "            \"Wiki-Vote.txt\",\n",
    "            \"wiki-Vote.txt\",\n",
    "            \"wiki_vote_data/Wiki-Vote.txt\",\n",
    "            \"../input/bda-assignment1/Wiki-Vote.txt\",\n",
    "            \"/kaggle/input/bda-assignment1/Wiki-Vote.txt\"\n",
    "        ]\n",
    "        for path in alternative_paths:\n",
    "            if os.path.exists(path):\n",
    "                data_path = path\n",
    "                break\n",
    "    \n",
    "    print(f\"Using data file: {data_path}\")\n",
    "    \n",
    "    # Create analyzer\n",
    "    analyzer = WikiGraphAnalyzer(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    \n",
    "    try:\n",
    "        # Clear existing data (optional - uncomment to start fresh)\n",
    "        # print(\"Clearing existing database...\")\n",
    "        # analyzer.clear_database()\n",
    "        \n",
    "        # Run analysis\n",
    "        results = analyzer.run_complete_analysis(data_path)\n",
    "        \n",
    "        print(\"\\n‚úÖ Analysis completed successfully!\")\n",
    "        \n",
    "        # Optionally save results to file\n",
    "        try:\n",
    "            import json\n",
    "            with open(\"neo4j_analysis_results.json\", \"w\") as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            print(\"üìÑ Results saved to neo4j_analysis_results.json\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save results to file: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        analyzer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
